{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISYS2407 Information Systems Solutions & Design\n",
    "\n",
    "# Binary Classification Algorithms\n",
    "\n",
    "###### Â© France and Christopher Cheong 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library for pickling\n",
    "import joblib\n",
    "\n",
    "# Library for splitting the data into train and test sets\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Other libraries will be imported later as and when they are needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Load the cleaned data\n",
    "\n",
    "#### Pickled file must exist in your folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the pickled file\n",
    "diabetes_df = joblib.load('diabetes-cleaned.pkl')  \n",
    "\n",
    "# Check\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the features in variable X (uppercase as there are multiple features)\n",
    "\n",
    "# Features are variables that affect the target/label\n",
    "# So, it's all the columns excluding the target column\n",
    "# However, you may also use a subset of features previously identified as best features\n",
    "# You might want to experiment with both the full set and the best features\n",
    "feature_cols = [\n",
    "    'num_pregnancies', \n",
    "    'glucose', \n",
    "    'blood_pressure', \n",
    "    'skin_thickness',\n",
    "    'insulin', \n",
    "    'bmi', \n",
    "    'pedigree', \n",
    "    'age'\n",
    "]\n",
    "\n",
    "X = diabetes_df[feature_cols]\n",
    "#print('X:\\n', X)\n",
    "\n",
    "# Store the labels/target in variable y (lower case as its a single value)\n",
    "y = diabetes_df['outcome']\n",
    "#print('y:\\n', y)\n",
    "\n",
    "# Split into train/test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, # keep 20% for testing\n",
    "                                                    random_state=2 # pass an int for reproducible rtesult\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Algorithm 1:  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate model and fit on training data\n",
    "#lr_model = LogisticRegression(solver='lbfgs')\n",
    "#lr_model.fit(X_train, y_train)\n",
    "# Note the above 2 steps can be combined into a single step\n",
    "# Warning: TOTAL NO. of ITERATIONS REACHED LIMIT, Increase the number of iterations (max_iter)\n",
    "#lr_model = LogisticRegression(solver='lbfgs').fit(X_train, y_train)\n",
    "lr_model = LogisticRegression(solver='lbfgs', max_iter=200).fit(X_train, y_train) # default max_iter is 100\n",
    "\n",
    "# Predict using test data\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Quick check\n",
    "# Print a few elements from the vector\n",
    "# Slice the elements of the array from the beginning to index 5 (not included)\n",
    "print(y_pred[:5]) # [:5] print first 5 elements\n",
    "# Examples: https://www.w3schools.com/python/numpy_array_slicing.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Algorithm 2:  KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate model and fit on training data\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "\n",
    "# Predict using test data\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Quick check\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Algorithm 3: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model library\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate model and fit on training data\n",
    "svm_model = SVC(kernel='linear', \n",
    "            class_weight='balanced', # penalize\n",
    "            probability=True).fit(X_train, y_train)\n",
    "\n",
    "# Predict using test data\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Quick check\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Algorithm 4: Decision Trees (Random Forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate model and fit on training data\n",
    "rf_model = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "\n",
    "# Predict using test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Quick check\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Algorithm 5:  Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model library\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Instantiate model and fit on training data\n",
    "nb_model = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "# Predict using test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Quick check\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
